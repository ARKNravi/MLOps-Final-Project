name: MLOps CI/CD Pipeline

on:
    push:
        branches:
            - main
    pull_request:
        branches:
            - main

jobs:
    monitoring_setup:
        runs-on: ubuntu-latest
        steps:
            - name: Checkout repository
              uses: actions/checkout@v2

            - name: Configure Grafana Cloud
              env:
                  GRAFANA_CLOUD_API_KEY: ${{ secrets.GRAFANA_CLOUD_API_KEY }}
                  GRAFANA_CLOUD_API_URL: ${{ secrets.GRAFANA_CLOUD_URL }}
                  PROMETHEUS_REMOTE_WRITE_URL: ${{ secrets.PROMETHEUS_REMOTE_WRITE_URL }}
                  LOKI_URL: ${{ secrets.LOKI_URL }}
              run: |
                  # Setup Prometheus remote write configuration
                  cat > prometheus.yml << EOF
                  global:
                    scrape_interval: 15s
                    evaluation_interval: 15s
                    
                  remote_write:
                    - url: ${PROMETHEUS_REMOTE_WRITE_URL}
                      basic_auth:
                        username: ${GRAFANA_CLOUD_API_KEY}
                        password: ${GRAFANA_CLOUD_API_KEY}
                        
                  scrape_configs:
                    - job_name: 'mlops-metrics'
                      static_configs:
                        - targets: ['localhost:8000']
                  EOF

                  # Verify configuration
                  echo "Testing connection to Grafana Cloud..."
                  curl -I -H "Authorization: Bearer ${GRAFANA_CLOUD_API_KEY}" ${GRAFANA_CLOUD_API_URL}/api/health

            - name: Verify Grafana Cloud Integration
              env:
                  GRAFANA_CLOUD_API_KEY: ${{ secrets.GRAFANA_CLOUD_API_KEY }}
                  PROMETHEUS_API_KEY: ${{ secrets.PROMETHEUS_API_KEY }}
                  LOKI_API_KEY: ${{ secrets.LOKI_API_KEY }}
                  GRAFANA_CLOUD_URL: "https://arknravi.grafana.net"
                  PROMETHEUS_REMOTE_WRITE_URL: "https://prometheus-prod-37-prod-ap-southeast-1.grafana.net/api/prom/push"
                  LOKI_URL: "https://logs-prod-020.grafana.net"
                  PROMETHEUS_USERNAME: "1902030"
                  LOKI_USERNAME: "1050298"
              run: |
                  # Check Grafana API health
                  echo "Checking Grafana API..."
                  GRAFANA_HEALTH=$(curl -s -H "Authorization: Bearer ${GRAFANA_CLOUD_API_KEY}" \
                      "${GRAFANA_CLOUD_URL}/api/health")
                  echo "Grafana Health: ${GRAFANA_HEALTH}"

                  # Check Prometheus metrics dengan basic auth
                  echo "Checking Prometheus metrics..."
                  PROM_RESPONSE=$(curl -s \
                      -u "${PROMETHEUS_USERNAME}:${PROMETHEUS_API_KEY}" \
                      "https://prometheus-prod-37-prod-ap-southeast-1.grafana.net/api/prom/api/v1/query?query=up")
                  echo "Prometheus Response: ${PROM_RESPONSE}"

                  # Check Loki logs dengan basic auth
                  echo "Checking Loki logs..."
                  LOKI_RESPONSE=$(curl -s \
                      -u "${LOKI_USERNAME}:${LOKI_API_KEY}" \
                      "https://logs-prod-020.grafana.net/loki/api/v1/labels")
                  echo "Loki Response: ${LOKI_RESPONSE}"

                  # Print dashboard URL
                  echo "Grafana Dashboard URL: ${GRAFANA_CLOUD_URL}"

                  # Verify all responses
                  if echo "${GRAFANA_HEALTH}" | grep -q "database.*ok"; then
                      echo "✅ Grafana connection successful"
                  else
                      echo "❌ Grafana connection failed"
                      exit 1
                  fi

                  if ! echo "${PROM_RESPONSE}" | grep -q "error"; then
                      echo "✅ Prometheus connection successful"
                  else
                      echo "❌ Prometheus connection failed"
                      exit 1
                  fi

                  if ! echo "${LOKI_RESPONSE}" | grep -q "error"; then
                      echo "✅ Loki connection successful"
                  else
                      echo "❌ Loki connection failed"
                      exit 1
                  fi

    # Step 1: Build Base Image with Dependencies
    build_and_cache_dependencies:
        runs-on: ubuntu-latest
        steps:
            - name: Checkout repository
              uses: actions/checkout@v2

            - name: Log in to Docker Hub
              uses: docker/login-action@v2
              with:
                  username: ${{ secrets.DOCKER_USERNAME }}
                  password: ${{ secrets.DOCKER_PASSWORD }}

            - name: Build and Push Dependency Image
              run: |
                  docker build -t ${{ secrets.DOCKER_USERNAME }}/mlops_dependencies:latest .
                  docker push ${{ secrets.DOCKER_USERNAME }}/mlops_dependencies:latest

    # Step 2: Training and Evaluating Model with Prometheus and Grafana
    train_and_evaluate:
        runs-on: ubuntu-latest
        needs: build_and_cache_dependencies
        services:
            grafana:
                image: grafana/grafana:latest
                ports:
                    - 3000:3000
            mlflow:
                image: ghcr.io/mlflow/mlflow:v2.18.0rc0
                ports:
                    - 5000:5000

        steps:
            - name: Checkout repository
              uses: actions/checkout@v2

            # Set up Prometheus configuration directory and remove existing Prometheus container if exists
            - name: Set up Prometheus configuration and start Prometheus
              run: |
                  mkdir -p ./prometheus_config
                  cp prometheus.yml ./prometheus_config/prometheus.yml

                  # Stop and remove existing Prometheus container
                  docker stop prometheus || true
                  docker rm prometheus || true

                  # Start Prometheus container
                  docker run -d --name prometheus -p 9090:9090 \
                    -v $(pwd)/prometheus_config/prometheus.yml:/etc/prometheus/prometheus.yml prom/prometheus:latest

            # Debugging: Log environment variables to ensure they are set correctly
            - name: Debugging - Log environment variables
              run: |
                  echo "DAGSHUB_USERNAME: ${{ secrets.DAGSHUB_USERNAME }}"
                  echo "DAGSHUB_TOKEN: ${{ secrets.DAGSHUB_TOKEN }}"
                  echo "SUPABASE_S3_ENDPOINT: ${{ secrets.SUPABASE_S3_ENDPOINT }}"
                  echo "SUPABASE_S3_REGION: ${{ secrets.SUPABASE_S3_REGION }}"
                  echo "SUPABASE_S3_ACCESS_KEY_ID: ${{ secrets.SUPABASE_S3_ACCESS_KEY_ID }}"
                  echo "SUPABASE_S3_SECRET_ACCESS_KEY: ${{ secrets.SUPABASE_S3_SECRET_ACCESS_KEY }}"

            - name: Pull and Run Dependency Image
              env:
                  SUPABASE_S3_ENDPOINT: ${{ secrets.SUPABASE_S3_ENDPOINT }}
                  SUPABASE_S3_REGION: ${{ secrets.SUPABASE_S3_REGION }}
                  SUPABASE_S3_ACCESS_KEY_ID: ${{ secrets.SUPABASE_S3_ACCESS_KEY_ID }}
                  SUPABASE_S3_SECRET_ACCESS_KEY: ${{ secrets.SUPABASE_S3_SECRET_ACCESS_KEY }}
                  DAGSHUB_USERNAME: ${{ secrets.DAGSHUB_USERNAME }}
                  DAGSHUB_TOKEN: ${{ secrets.DAGSHUB_TOKEN }}
              run: |
                  # Pull the Docker dependency image with retry mechanism
                  n=0
                  until [ "$n" -ge 5 ]
                  do
                      docker pull ${{ secrets.DOCKER_USERNAME }}/mlops_dependencies:latest && break
                      n=$((n+1))
                      echo "Retrying in 5 seconds..."
                      sleep 5
                  done

                  # Run the Docker container with dependencies
                  docker run --rm \
                      -e SUPABASE_S3_ENDPOINT="$SUPABASE_S3_ENDPOINT" \
                      -e SUPABASE_S3_REGION="$SUPABASE_S3_REGION" \
                      -e SUPABASE_S3_ACCESS_KEY_ID="$SUPABASE_S3_ACCESS_KEY_ID" \
                      -e SUPABASE_S3_SECRET_ACCESS_KEY="$SUPABASE_S3_SECRET_ACCESS_KEY" \
                      -e DAGSHUB_USERNAME="$DAGSHUB_USERNAME" \
                      -e DAGSHUB_TOKEN="$DAGSHUB_TOKEN" \
                      -e MLFLOW_TRACKING_URI="http://localhost:5000" \
                      -v ${{ github.workspace }}:/app -w /app ${{ secrets.DOCKER_USERNAME }}/mlops_dependencies:latest bash -c "
                        echo 'Starting training...' &&
                        echo 'Environment Variables in Container:' &&
                        echo 'DAGSHUB_USERNAME: $DAGSHUB_USERNAME' &&
                        echo 'DAGSHUB_TOKEN: $DAGSHUB_TOKEN' &&
                        echo 'SUPABASE_S3_ENDPOINT: $SUPABASE_S3_ENDPOINT' &&
                        echo 'SUPABASE_S3_REGION: $SUPABASE_S3_REGION' &&
                        echo 'SUPABASE_S3_ACCESS_KEY_ID: $SUPABASE_S3_ACCESS_KEY_ID' &&
                        echo 'SUPABASE_S3_SECRET_ACCESS_KEY: $SUPABASE_S3_SECRET_ACCESS_KEY' &&

                        # Git configuration
                        git config --global user.email 'actions@github.com' &&
                        git config --global user.name 'GitHub Actions' &&
                        
                        # Stop tracking dataset and model folders with Git
                        git rm -r --cached dataset || true &&
                        git rm -r --cached model || true &&
                        git commit -m 'Stop tracking dataset and model' --allow-empty &&
                        
                        # DVC setup and configuration
                        dvc remote add -d supabase-s3 s3://MLOps --force &&
                        dvc remote modify supabase-s3 endpointurl '$SUPABASE_S3_ENDPOINT' &&
                        dvc remote modify supabase-s3 region '$SUPABASE_S3_REGION' &&
                        dvc remote modify supabase-s3 access_key_id '$SUPABASE_S3_ACCESS_KEY_ID' &&
                        dvc remote modify supabase-s3 secret_access_key '$SUPABASE_S3_SECRET_ACCESS_KEY' &&
                        
                        # Pull the dataset from the DVC remote
                        dvc pull &&
                        
                        # Check dataset directory for debugging
                        echo 'Contents of dataset/train directory:' &&
                        ls /app/dataset/train &&
                        
                        # Run the training script
                        python script/train.py &&
                        
                        # Push updated model and dataset changes back to DVC remote
                        dvc push &&

                        # Run the test script
                        python script/test.py
                      "

    # Step 3: Build and Push Final Docker Image with Model
    build_and_push_docker:
        runs-on: ubuntu-latest
        needs: train_and_evaluate
        steps:
            - name: Checkout repository
              uses: actions/checkout@v2

            - name: Log in to Docker Hub
              uses: docker/login-action@v2
              with:
                  username: ${{ secrets.DOCKER_USERNAME }}
                  password: ${{ secrets.DOCKER_PASSWORD }}

            - name: Build Docker Image with Model
              run: |
                  docker build -t ${{ secrets.DOCKER_USERNAME }}/mlops_project:latest .

            - name: Push Docker Image
              run: |
                  docker push ${{ secrets.DOCKER_USERNAME }}/mlops_project:latest
